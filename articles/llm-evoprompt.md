---
title: "進化的アルゴリズムで自動プロンプトエンジニアリング"
emoji: "📃"
type: "tech"
topics: ["ChatGPT", "LLM", "プロンプトエンジニアリング", "遺伝的アルゴリズム", "LLMOps"]
published: false
---

# 本記事の内容

- **プロンプトエンジニアリング**を**自動**で行う手法を紹介するよ
- **進化的アルゴリズム**を使った「EVOPROMPT」という手法だよ
    - 遺伝的アルゴリズム(GA)
    - 差分進化法(DE)
- ICLR2024に採択された論文の手法を紹介するよ
    - [Connecting large language models with evolutionary algorithms yields powerful prompt optimizers](https://arxiv.org/abs/2309.08532)

# プロンプトエンジニアリング×進化的アルゴリズム

ChatGPTなどのLLMから正確な回答を引き出すには、プロンプトエンジニアリングが重要です。
しかし、効果的なプロンプトを作成するには多くの試行錯誤が必要で、多くの時間と労力を費やす必要があります。

そこで近年注目されているのが、**プロンプトエンジニアリングを自動化**する技術です。

本記事では、**進化的アルゴリズム**を使った自動プロンプトエンジニアリング手法「EVOPROMPT」を紹介します。

出典は、ICLR2024にも採択されたこちらの論文です。

https://arxiv.org/abs/2309.08532

# アルゴリズムの内容

進化的アルゴリズムの主な手法として、

- 遺伝的アルゴリズム（GA; Genetic Algorithm）
- 差分進化（DE; Differential Evolution）

が挙げられます。本論文では、この2つの手法それぞれを用いてプロンプトエンジニアリングを行っています。

## 遺伝的アルゴリズム（GA）の場合

![](/images/llm-evoprompt/evoprompt_algorithm2.png)

### 1. 初期化
まず初期集団として、$N$個のプロンプト集合を$P_0 = \{p_1, \cdots p_N\}$とおきます。
また、それぞれのプロンプト$p_i$を使ったときのLLM出力に対する評価スコア$s_i$を割り当て、$S_0 = \{s_1, s_2, \cdots, s_N\}$としておきます。

### 2. 繰り返し処理

以下の操作を、$T$回だけ繰り返します。ただし、「$t$」は繰り返し回数（$t=1,\cdots,T$）。

1. **Selection**
    - 現在のプロンプト集合$P_{t-1}$から、2個のプロンプト$p_{r_1},p_{r_2}$を親プロンプトとして選択します。
    - 選択の方法としては、ルーレット選択、トーナメント選択、ランダム選択が考えられますが、本論文では**ルーレット選択**を用いています。
        :::details ルーレット選択とは
        ルーレット選択では、スコア$s_i$の分布に従ってプロンプトをランダムに選択します。
        つまり、プロンプト$i$が選ばれる確率を

        $$\displaystyle p_i = \frac{s_i}{\sum_{j=1}^{N}s_j}$$
        
        として、スコアが高いプロンプトほど選ばれやすくなるようにします。
        :::

2. **Evolution**
    - 選ばれたプロンプト$p_{r_1},p_{r_2}$をもとに、遺伝計算を行って新プロンプト$p_i'$を生成します。
    - 遺伝計算では、LLMを使います。具体的には、下の画像のようなプロンプトをLLMに与えて**交叉**(cross over)と**突然変異**(mutation)を行います。
    ![](/images/llm-evoprompt/evoprompt_fig1.png)
        - **Cross Over**:
            - 2つのプロンプト$p_{r_1},p_{r_2}$を与えて、「これらのプロンプトを交叉させなさい」と指示する。
        - **Mutation**:
            - 「上記で交叉させたプロンプトを突然変異させたものを<prompt>と</prompt>で囲って出力しなさい」と指示する。

3. **Evaluation**:
    - 新プロンプト$p_i'$を評価して、そのスコアを$s_i'$とします。

以上の**Selection**から**Evaluation**までの操作を$N$回繰り返します($i=1,\cdots,N$)。

4. **Update**:
上記$N$個の結果を、現在のプロンプト集合$P_{t-1}$とスコア集合$S_{t-1}$にガッチャンコし（要素の数は$2N$個になる）、スコアが上位$N$個のプロンプトのみを保持します。つまり

$$
\begin{align*}
S_t \leftarrow \text{Top-}N(S_{t-1}\cap\{s_1', s_2', \cdots, s_N'\})\\
P_t \leftarrow \underset{\text{using }S_t}{\text{Top-}N}(P_{t-1}\cap\{p_1', p_2', \cdots, p_N'\})
\end{align*}
$$


### 3. 終了処理

上記の繰り返し処理が終わったら、プロンプト集合$P_T$から最もスコアの高いプロンプトをベストプロンプト$p^*$として出力します。


## 差分進化法（DE）の場合

![](/images/llm-evoprompt/evoprompt_algorithm3.png)

### 1. 初期化

初期集団として、$N$個のプロンプト集合を$P_0 = \{p_1, \cdots p_N\}$とおきます。
また、それぞれのプロンプト$p_i$に対してスコア$s_i$を割り当て、$S_0 = \{s_1, s_2, \cdots, s_N\}$としておきます。

### 2. 繰り返し処理

以下の操作を、$T$回だけ繰り返します。ただし、「$t$」は繰り返し回数（$t=1,\cdots,T$）。

現在のプロンプト集合$P_{t-1}$からプロンプト$p_i$を順に取り出し、以下の操作を行います。

1. **Sample donors**
    - 2個のプロンプト$p_{r_1},p_{r_2}(r_1\ne r_2 \ne i)$を親プロンプトとして$P_{t-1}$からランダムに選択します。
    - 選択の方法としては、GA同様に**ルーレット選択**を用いています。

2. **Evolution**
    - プロンプト$p_i,p_{r_1},p_{r_2}$と現時点でのベストプロンプト$p_\text{best}$をもとに、差分進化を用いて新プロンプト$p_i'$を生成します。
    - 差分進化では、親プロンプト$p_{r_1},p_{r_2}$から差分を取り、それを突然変異させたものをプロンプト$p_i$に足します。最後に、現時点でのベストプロンプト$p_{\text{best}}$と交叉させて新プロンプト$p_i'$を生成します。
    - 具体的には以下の画像のようになります（$p_{r_1}$:`Prompt 1`、$p_{r_2}$:`Prompt 2`、$p_i$:`Prompt 3`、$p_{\text{best}}$:`Basic Prompt`）。
    ![](/images/llm-evoprompt/evoprompt_fig2.png)

3. **Selection**
    - 元プロンプト$p_i$と新プロンプト$p_i'$のスコアを比較して、$p_i'$の方が良ければ$p_i$を$p_i'$に置き換えます。

### 3. 終了処理

上記の繰り返し処理が終わったら、プロンプト集合$P_T$から最もスコアの高いプロンプトをベストプロンプト$p^*$として出力します。


# 実験結果

## 他のプロンプトと比べて精度はどうか？

![](/images/llm-evoprompt/evoprompt_table1.png)

手動プロンプト(MI, NI, PromptSource)や、自動プロンプト最適化手法(APE, APO)を様々なベンチマークデータセットに適用した結果が示されています。

- 手動によるプロンプトや、従来の自動最適化手法よりも有意に精度が向上している。
- 主観性分類タスク(Subj)では、精度がDEの方がGAよりも5ポイントも高い。**GAよりもDEは局所最適に陥りづらく、初期プロンプトが高品質でない場合に有効**。

## 集団サイズを増やすと精度はどうか？

![](/images/llm-evoprompt/evoprompt_fig6.png)

横軸が集団サイズ、縦軸が精度を示しています。左のグラフがSST-5(感情分類タスク)、中央がSubj(主観性分類タスク)、右がASSET(テキスト単純化タスク)の結果です。

概ね、**集団サイズが大きくなるにつれて精度が向上**していることがわかります。

また、グラフの縦軸のスケールを見てみると、Subj(主観性分類タスク)の場合は他の2つのタスクに比べて精度の上昇幅が大きいことがわかります。

論文では、比較的単純なタスクでは集団サイズを大きくしてもあまり効果は得られないが、**複雑なタスクでは集団サイズを大きくすることで精度が向上するのではないか**という考察がなされています。

もちろん、集団サイズを大きくすると計算コストが増えるので、その辺りのトレードオフも考慮する必要があります。

## 繰り返し回数を増やすと精度はどうか？

![](/images/llm-evoprompt/evoprompt_fig7.png)

横軸が繰り返し回数、縦軸が集団全体のベストスコア(実線)と平均スコア(点線)を示しています。

いずれのデータセットでも進化が進むにつれてスコアがきちんと向上していることがわかります。


## 繰り返し数に伴ってプロンプトはどのように変化するか？

![](/images/llm-evoprompt/evoprompt_fig9.png)

左のグラフがプロンプト長の平均値、中央がプロンプト長の分散、右が変異した新しい単語の個数を示しています。

特徴としては、**DEの方がGAよりも長いプロンプトを生成しており、長さのばらつきも大きい**ことがわかります。

また、右のグラフの終盤を見ると、**DEはGAよりも多くの新しい単語を変異させている**ことがわかります。これはDEは局所最適から脱出できる可能性がGAよりも高いことを示唆しています。

## 最適化後のプロンプト具体例

![](/images/llm-evoprompt/evoprompt_table14.png)

上記は、論文の`Table 14`で示されているプロンプトの具体例の抜粋です。

日本語に翻訳するとこんな感じです。

- **Manual Prompt**:
    > 主観性分類タスクを実行してください。文が与えられたら、['主観的', '客観的']からラベルを割り当ててください。他のテキストを入れずに、ラベルだけを返してください。
- **Natural Instruction**:
    > このタスクでは、レビューの文章が与えられます。その文の意見が主観的であれば「主観的」、客観的であれば「客観的」と分類するタスクです。
- **EVOPROMPT**:
    > レビューや意見の主観性を示すための入力と出力のペアを作成し、客観的な入力と主観的な入力を区別しながら、個人的な意見の例や主観的な見解のイラストを作成して、判断や視点の主観性を示すことができるようにしてください。


最適化後はちょっと小難しい指示になっていますが、精度は49.75から77.60まで向上しています。なかなかすごいですね。


# 最後に

本記事では、進化的アルゴリズムを用いた自動プロンプトエンジニアリング手法「EVOPROMPT」を紹介しました。EVOPROMPTは、手動プロンプトと比較して精度が向上し、試行錯誤の時間削減にもなります。

また、開発フェーズだけではなく運用フェーズでも自動最適化は有用かもしれません。
新しいモデルを適用する前に、EVOPROMPTでプロンプトを自動で最適化してLLMの能力を最大限に引き出すことができそうです。


# 参考文献

[1] Guo, Qingyan, et al. "Connecting large language models with evolutionary algorithms yields powerful prompt optimizers." arXiv preprint arXiv:2309.08532 (2023). 

https://arxiv.org/abs/2309.08532
